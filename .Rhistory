install.packages("readxl")
install.packages("XLConnect")
install.packages("XML")
library("XML")
install.packages("jsonlite")
library(jsonlite)
require(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR(admin_password= "bawitdaba")
library(pacman)
library(RMySQL)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
install.packages("httr")
packages(httr)
library(httr)
install.packages("sqldf")
library(sqldf)
library(RMySQL)
datalink <- dbConnect(MySQL(),host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
setwd("/Users/massimodimichele/Documents/Coursera/Data Science - Johns Hopkins/Getting and Cleaning Data/Week 2/test folder/")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl,destfile="communities.csv", method="curl")
# Comm <- read.csv("communities.csv")
acs <- fread("Communities.csv")
library(data.table)
acs <- fread("Communities.csv")
head(acs)
acs2 <- sqldf("select pwgtp1 from acs where AGEP < 50")
list1 <- unique(acs$AGEP)
dim(list1)
class(list1)
head(list1)
list1
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
head(htmlCode)
?nchar
nchar(htmlCode[10])
nchar(htmlCode[10,20,30,100])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,14,header=TRUE)
close(con)
head(filecode)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,14,header=TRUE,skip = 2)
close(con)
head(filecode)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,14,header=TRUE,skip = 3)
close(con)
head(filecode)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,13,header=TRUE,skip = 3)
close(con)
head(filecode)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,13,header=TRUE,skip = 4)
close(con)
head(filecode)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,13,header=FALSE,skip = 3)
close(con)
head(filecode)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,13,header=FALSE,skip = 4)
close(con)
head(filecode)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,14,header=FALSE,skip = 4)
close(con)
head(filecode)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,c(14,13,13,13,13),header=FALSE,skip = 4)
close(con)
head(filecode)
my_data <- filecode[,5]
head(mydata)
head(my_data)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,c(14,4,10,4,10,4,10,4,10),header=FALSE,skip = 4)
close(con)
head(filecode)
my_data <- filecode[,9]
head(my_data)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,c(14,4,9,4,9,4,9,4,9),header=FALSE,skip = 4)
close(con)
head(filecode)
my_data <- filecode[,9]
head(my_data)
class(my_data)
sum(my_data)
sum(as.numeric(my_data))
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
filecode <- read.fwf(con,c(14,4,9,4,9,4,9,4,9),header=FALSE,skip = 4)
close(con)
head(filecode)
my_data <- filecode[,4]
head(my_data)
sum(as.numeric(my_data))
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
# filecode <- read.fwf(con,c(14,4,9,4,9,4,9,4,9),header=FALSE,skip = 4)
filecode <- read.fwf(con,c(14,5,8,5,8,5,8,5,8),header=FALSE,skip = 4)
close(con)
head(filecode)
my_data <- filecode[,4]
head(my_data)
sum(as.numeric(my_data))
library(dplyr)
library(tidyr)
getUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(getUrl,"GDP.csv")
GDP <- read.csv("GDP.csv", skip = 4, nrows = 190)
# GDP$X.3 <- as.numeric(GDP$X.3)
GDP <- GDP[,-c(3,6:10)]
getUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(getUrl,"Edu.csv")
Edu <- read.csv("Edu.csv")
# mergedData <- merge(GDP,Edu,by.x = "X",by.y = "CountryCode",all=FALSE)
# mergedData$X.3 <- as.numeric(mergedData$X.3)
mergedData = merge(GDP, Edu, by = "X.4")
newDf <- arrange(mergedData, desc(X.2))
newDf[13,"Short.Name"]
newDf <- arrange(mergedData, desc(X.4))
mergedData = merge(GDP, Edu, by.x = "CountryCode", by.y = "X")
mergedData = merge(Edu,GDP, by.x = "CountryCode", by.y = "X")
newDf <- arrange(mergedData, desc(X.4))
newDf[13,"Short.Name"]
mergedData = merge(GDP, Edu, by.x = "X", by.y = "CountryCode")
newDf <- arrange(mergedData, desc(X.4))
newDf[13,"Short.Name"]
newDf <- mergedData[order(mergedData$X.4)]
newDf <- mergedData[order(mergedData$X.4),]
newDf <- mergedData[order(as.numeric(mergedData$X.4)),]
newDf <- mergedData[order(as.character(mergedData$X.4)),]
newDf <- mergedData[order(as.double(mergedData$X.4)),]
View(newDf)
class(mergedData$X.4)
install.packages("varhandle")
library(varhandle)
unfactor(newDf$X.4)
foo <- unfactor(newDf$X.4)
class(foo)
foo <- as.numeric(foo)
head(foo)
foo <- unfactor(newDf$X.4)
newDf <- mergedData[order(unfactor(mergedData$X.4)),]
class(mergedData$X.4)
class(newDf$X.4)
foo <- unfactor(newDf$X.4)
head(foo)
foo <- as.double(foo)
foo <- unfactor(newDf$X.4)
class(foo)
foo <- as.numeric(levels(foo))
class(foo)
foo
foo <- unfactor(newDf$X.4)
class(foo)
foo <- unfactor(newDf$X.4)[foo]
foo
getUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(getUrl,"GDP.csv")
GDP <- read.csv("GDP.csv", skip = 4, nrows = 190)
class(GDP$X.4)
?fread
library(plyr)
?fread
library(data.table)
GDP = fread("GDP.csv", skip=4, nrows = 190, select = c(1, 2, 4, 5), col.names=c("CountryCode", "Rank", "Economy", "Total"))
class(GDP$Total)
mergedData = merge(GDP, Edu, by.x = "X", by.y = "CountryCode")
newDf <- arrange(mergedData, desc(X.4))
newDf[13,"Short.Name"]
Edu <- fread("Edu.csv")
mergedData = merge(GDP, Edu, by.x = "X", by.y = "CountryCode")
newDf <- arrange(mergedData, desc(X.4))
newDf[13,"Short.Name"]
class(GDP$Total)
GDP$Total <- GDP$Total(as.numeric(GDP$Total))
GDP$Total <- GDP$Total[(as.numeric(GDP$Total)),]
class(GDP$Total)
GDP$Total <- as.numeric(GDP$Total)
GDP = fread("GDP.csv", skip=4, nrows = 190, select = c(1, 2, 4, 5), col.names=c("CountryCode", "Rank", "Economy", "Total"))
newDf <- arrange(mergedData, desc(X.4))
class(newDf)
class(newDf$X.4)
mergedData = merge(GDP, Edu, by = "CountryCode")
newDf <- arrange(mergedData, desc(X.4))
newDf <- arrange(mergedData, desc(CountryCode))
class(newDf$CountryCode)
str(newDf)
newDf <- arrange(mergedData, desc(Rank))
newDf[13,"Short.Name"]
newDf[13,"Economy"]
newDf[13,Economy]
nrows(newDf)
nrow(newDf)
Esize <- group_by(newDf,`Income Group`)
head(Esize)
summarize(Esize, Avg = mean(Total))
class(newDf)
head(newDf)
class(newDf$Total)
setwd("/Users/massimodimichele/Documents/Coursera/Data Science - Johns Hopkins/5 - Reproducible Research/Week 2/Assignment")
alldata <- read.csv("activity.csv")
alldata$date <- as.Date(alldata$date, format = "%Y-%m-%d")
#calculate total number of steps taken per day
daystep <- (with(alldata,tapply(steps,date,sum)))
print(as.data.frame(daystep))
# Make a histogram of the total number of steps taken each day
hist(daystep, breaks = 20, xlab = "Number of steps taken each day", col = "red",
main = "Histogram of steps taken each day")
# Calculate and report the mean and median of the total number of steps taken per day
library(data.table)
meanmed <- alldata
meanmed %>% group_by(date) %>% summarize(mean = mean(steps), median = median(steps))
# Make a time series plot (i.e. ğšğš¢ğš™ğš = "ğš•") of the 5-minute interval
# (x-axis) and the average number of steps taken, averaged across all days (y-axis)
tseries <- as.data.frame(with(alldata,tapply(steps,interval,mean,na.rm=TRUE)))
plot(y=t(tseries),
x=row.names(tseries),
typ="l",
lwd=2,
col="blue",
main="Average number of step taken across days, by interval",
ylab="Average number of steps",
xlab = "Interval")
# Which 5-minute interval, on average across all the days in the dataset,
# contains the maximum number of steps?
tseries[which(tseries==max(tseries)),]
# Calculate and report the total number of missing values in the dataset
# (i.e. the total number of rows with ğ™½ğ™°s)
sum(is.na(alldata))
# Devise a strategy for filling in all of the missing values in the dataset.
# The strategy does not need to be sophisticated. For example, you could use
# the mean/median for that day, or the mean for that 5-minute interval, etc.
# isolate days with NAs
NAs <- alldata %>% group_by(date) %>% summarize(nas = sum(is.na(steps))) %>% filter(nas>0)
# It seems that NAs exist for whole days only, so appropriate strategy is to replace NAs with interval
# across days
# Create a new dataset that is equal to the original dataset but with the missing data filled in.
repdata <- alldata
i = 1
for (i in (1:nrow(repdata))) {
if (is.na(repdata$steps[i])) {
repdata$steps[i] <- mean(subset(alldata,
alldata$interval==alldata$interval[i])[,1],
na.rm = TRUE)
}
i = i+1
}
# Make a histogram of the total number of steps taken each day and Calculate and report the mean
# and median total number of steps taken per day. Do these values differ from the estimates
# from the first part of the assignment? What is the impact of imputing missing data on the
# estimates of the total daily number of steps?
repdaystep <- (with(repdata,tapply(steps,date,sum)))
hist(repdaystep, breaks = 20, xlab = "Number of steps taken each day", col = "red",
main = "Histogram of steps taken each day")
reptseries <- as.data.frame(with(repdata,tapply(steps,interval,mean)))
lines(y=t(ctseries), x=row.names(reptseries), col = "red", lty=2, lwd=2)
# Data are now much more concentrated around the mean
repmeanmed <- repdata
repmeanmed %>% group_by(date) %>% summarize(mean = mean(steps), median = median(steps))
# Create a new factor variable in the dataset with two levels â€“ â€œweekdayâ€ and â€œweekendâ€
# indicating whether a given date is a weekday or weekend day.
repdata <- mutate(repdata,sapply(weekdays(alldata$date),
function(x) {
ifelse(x == "Saturday" | x == "Sunday",
"weekend",
"weekday")}))
colnames(repdata)[4]="day"
# Make a panel plot containing a time series plot (i.e. ğšğš¢ğš™ğš = "ğš•") of the 5-minute
# interval (x-axis) and the average number of steps taken, averaged across all weekday
# days or weekend days (y-axis). See the README file in the GitHub repository to see an
# example of what this plot should look like using simulated data.
tsweekday <- as.data.frame(with(subset(repdata, day == "weekday"),
tapply(steps,interval,mean)))
tsweekend <- as.data.frame(with(subset(repdata, day == "weekend"),
tapply(steps,interval,mean)))
par(mfrow=c(2,1), mar = c(4, 4, 2, 1), oma = c(0, 0, 2, 0))
plot(y=t(tsweekday),
x=row.names(tsweekday),
typ="l",
lwd=2,
col="blue",
main="Average number of step taken during weekdays",
ylab="Average number of steps",
xlab = "Interval")
plot(y=t(tsweekend),
x=row.names(tsweekend),
typ="l",
lwd=2,
col="blue",
main="Average number of step taken during weekends",
ylab="Average number of steps",
xlab = "Interval")
meanmed %>% group_by(date) %>% summarize(mean = mean(steps), median = median(steps))
